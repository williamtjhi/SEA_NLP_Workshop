{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6efad30",
   "metadata": {},
   "source": [
    "## A demo of a \"rich\" sentiment analysis done in English"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd7d292",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04951c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76232d",
   "metadata": {},
   "source": [
    "We are using the CSV version of the IMDB dataset, which can be downloaded from Kaggle (https://www.kaggle.com/avnika22/imdb-perform-sentiment-analysis-with-scikit-learn/data).\n",
    "\n",
    "We convert the sentiment labels from 0/1 to negative/positive to make the analysis more interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50c2915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text     label\n",
       "0  I grew up (b. 1965) watching and loving the Th...  negative\n",
       "1  When I put this movie in my DVD player, and sa...  negative\n",
       "2  Why do people who do not know what a particula...  negative\n",
       "3  Even though I have great interest in Biblical ...  negative\n",
       "4  Im a die hard Dads Army fan and nothing will e...  positive"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imdb_train = pd.read_csv(\"Datasets/IMDB/Train.csv\")\n",
    "imdb_test = pd.read_csv(\"Datasets/IMDB/Test.csv\")\n",
    "\n",
    "display(imdb_train.head(5))\n",
    "\n",
    "imdb_train[\"label\"].replace({0: \"negative\", 1: \"positive\"}, inplace=True)\n",
    "imdb_test[\"label\"].replace({0: \"negative\", 1: \"positive\"}, inplace=True)\n",
    "\n",
    "display(imdb_train.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a876ae8b",
   "metadata": {},
   "source": [
    "For high resource languages like English, an accurate sentiment analysis can be achieved using transfomers-based models. For low resource languages however, we cannot assume the existence of pre-trained transfomers models like BERT and GPT. At the minimum, in an LRL case, we can resort to TF-IDF based features for sentiment analysis. But a quick look at the `fasttext` library (https://fasttext.cc/docs/en/crawl-vectors.html), we can see that pre-trained word embeddings exist for major SEA languages (e.g. Indonesian, Vietnamese, Thai etc.). We therefore are using it for this sentiment analysis demo. \n",
    "\n",
    "We use `fasttext` for both English and Indonesian sentiment analysis in our demos to highlight that even at this basic infrastructure level, we can still perform a richer sentiment analysis for English than for SEA langauges like Indonesian.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fc486b",
   "metadata": {},
   "source": [
    "The pretrained English `fasttext` embedding can be downloaded from https://fasttext.cc/docs/en/crawl-vectors.html, but its size is in GB. \n",
    "\n",
    "Feel free to just watch this demo during the workshop. In your own time, after the session, you can download the `fasttext` embedding to do the full hands-on yourself. \n",
    "\n",
    "Do ignore the warning message when loading the embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b3c103d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model(\"Resources/cc.en.300.bin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c6e3b",
   "metadata": {},
   "source": [
    "When using `fasttext`, one can get the vector representation of a paragraph or a sentence by calling the function `get_sentence_vector`. We use the `apply` function from `pandas` to convert all the paragraphs in the train and test sets into their respective embedding vector representations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da125371",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train_df = pd.DataFrame.from_records(imdb_train.apply(lambda x: ft.get_sentence_vector(x[\"text\"]), axis=1))\n",
    "imdb_test_df = pd.DataFrame.from_records(imdb_test.apply(lambda x: ft.get_sentence_vector(x[\"text\"]), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "906fcbdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.001946</td>\n",
       "      <td>0.005286</td>\n",
       "      <td>-0.006489</td>\n",
       "      <td>0.032381</td>\n",
       "      <td>-0.018138</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>-0.000415</td>\n",
       "      <td>-0.007983</td>\n",
       "      <td>-0.003701</td>\n",
       "      <td>0.009630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>-0.000914</td>\n",
       "      <td>-0.053745</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>0.001679</td>\n",
       "      <td>-0.000670</td>\n",
       "      <td>0.072408</td>\n",
       "      <td>-0.017808</td>\n",
       "      <td>-0.004818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.011655</td>\n",
       "      <td>0.006336</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.052987</td>\n",
       "      <td>-0.024714</td>\n",
       "      <td>-0.013643</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>-0.006864</td>\n",
       "      <td>-0.001421</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>-0.005935</td>\n",
       "      <td>-0.060790</td>\n",
       "      <td>0.001817</td>\n",
       "      <td>-0.008390</td>\n",
       "      <td>0.004865</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0.076055</td>\n",
       "      <td>-0.022863</td>\n",
       "      <td>-0.011334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.006900</td>\n",
       "      <td>0.000868</td>\n",
       "      <td>0.010029</td>\n",
       "      <td>0.051313</td>\n",
       "      <td>-0.039501</td>\n",
       "      <td>-0.019932</td>\n",
       "      <td>0.005248</td>\n",
       "      <td>-0.010559</td>\n",
       "      <td>-0.005026</td>\n",
       "      <td>0.000838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.039897</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>-0.062426</td>\n",
       "      <td>0.004365</td>\n",
       "      <td>-0.013127</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.003938</td>\n",
       "      <td>0.078716</td>\n",
       "      <td>-0.009228</td>\n",
       "      <td>-0.004450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0 -0.001946  0.005286 -0.006489  0.032381 -0.018138 -0.006376 -0.000415   \n",
       "1 -0.011655  0.006336  0.003707  0.052987 -0.024714 -0.013643  0.006096   \n",
       "2 -0.006900  0.000868  0.010029  0.051313 -0.039501 -0.019932  0.005248   \n",
       "\n",
       "        7         8         9    ...       290       291       292       293  \\\n",
       "0 -0.007983 -0.003701  0.009630  ...  0.019738 -0.000914 -0.053745  0.009884   \n",
       "1 -0.006864 -0.001421  0.001961  ...  0.027027 -0.005935 -0.060790  0.001817   \n",
       "2 -0.010559 -0.005026  0.000838  ...  0.039897  0.000994 -0.062426  0.004365   \n",
       "\n",
       "        294       295       296       297       298       299  \n",
       "0 -0.011864  0.001679 -0.000670  0.072408 -0.017808 -0.004818  \n",
       "1 -0.008390  0.004865  0.004299  0.076055 -0.022863 -0.011334  \n",
       "2 -0.013127  0.005502  0.003938  0.078716 -0.009228 -0.004450  \n",
       "\n",
       "[3 rows x 300 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(imdb_train_df.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035f72e6",
   "metadata": {},
   "source": [
    "Now that we have the vector representation of the text dataset, we can perform a simple binary classification for sentiment analysis. We use `RandomForestClassifier` from `scikit-learn` in this demo. We can as well replace it with any other binary clasifier of out own choosing.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e87b4d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "model.fit(imdb_train_df, imdb_train[\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6043829a",
   "metadata": {},
   "source": [
    "After training, we can do prediction on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ca65c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sentiment = model.predict(imdb_test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7231d532",
   "metadata": {},
   "source": [
    "Get the accuracy and confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a32bbba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.81      0.81      0.81      2500\n",
      "    positive       0.81      0.81      0.81      2500\n",
      "\n",
      "    accuracy                           0.81      5000\n",
      "   macro avg       0.81      0.81      0.81      5000\n",
      "weighted avg       0.81      0.81      0.81      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(pred_sentiment, imdb_test[\"label\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "672655f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True negative</th>\n",
       "      <th>True positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Predicted negative</th>\n",
       "      <td>2017</td>\n",
       "      <td>478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted positive</th>\n",
       "      <td>483</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    True negative  True positive\n",
       "Predicted negative           2017            478\n",
       "Predicted positive            483           2022"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(imdb_test[\"label\"], pred_sentiment)\n",
    "cm_df = pd.DataFrame(cm, columns=[(\"True \" + i) for i in np.unique(pred_sentiment)], index = [(\"Predicted \" + i) for i in np.unique(pred_sentiment)])\n",
    "\n",
    "display(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ea5ce6",
   "metadata": {},
   "source": [
    "Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9507dbd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The movie is so bad!! ['negative']\n",
      "The movie is so nice. ['positive']\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"The movie is so bad!!\"\n",
    "prediction = model.predict(ft.get_sentence_vector(sample_text).reshape(1, -1))\n",
    "print(sample_text, prediction)\n",
    "\n",
    "sample_text = \"The movie is so nice.\"\n",
    "prediction = model.predict(ft.get_sentence_vector(sample_text).reshape(1, -1))\n",
    "print(sample_text, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d704155",
   "metadata": {},
   "source": [
    "### Adding NER into the mix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4480a04",
   "metadata": {},
   "source": [
    "In Engliish, we can go beyond a simple sentiment analysis as demonstrated up to this point. For example, we can filter the sentiment only for those reviews that make references to PERSON (e.g. because we care more about the reputations of some people, for example).  \n",
    "\n",
    "The following shows how we can perform Named Entity Recognition (NER), to filter the sentiments on the reviews that mention any PERSON; while ignoring the rests. NER is not something that is not necessarily available for some SEA languages. \n",
    "\n",
    "We use a popular NER library for English, `spacy` (https://spacy.io/). Another alternative would be `stanza` (https://stanfordnlp.github.io/stanza/). But `spacy` is more optimised for industry use than `stanza` in general. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03cf2c25",
   "metadata": {},
   "source": [
    "If this is your first time using `spacy`, there is need to download the English model first by executing the command below in your environment in the command line:\n",
    "\n",
    "`python -m spacy download en_core_web_sm`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f183676",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e6033b",
   "metadata": {},
   "source": [
    "We set up the `spacy` pipeline for NER below, and tag as `True` the IMDB reviews in the test set that contain any PERSON entity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27825aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_include_person = []\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "for doc in nlp.pipe(imdb_test[\"text\"], disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    imdb_include_person.append(\"PERSON\" in [(ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9a3837",
   "metadata": {},
   "source": [
    "Show the first few reviews that make reference to a PERSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5658edb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily. But then one day a tragic happenstance occurred. After a White Sox game ended I realized that the remote was all the way on the other side of the room somehow. Now I could have just gotten up and walked across the room to get the remote, or even to the TV to turn the channel. But then why not just get up and walk across the country to watch TV in another state? \"Nuts to that\", I said. So I decided to just hang tight on the couch and take whatever Fate had in store for me. What Fate had in store was an episode of this show, an episode about which I remember very little except that I had once again made a very broad, general sweeping blanket judgment based on zero objective or experiential evidence with nothing whatsoever to back my opinions up with, and once again I was completely right! This show is a total crud-pie! Belushi has all the comedic delivery of a hairy lighthouse foghorn. The women are physically attractive but too Stepford-is to elicit any real feeling from the viewer. There is absolutely no reason to stop yourself from running down to the local TV station with a can of gasoline and a flamethrower and sending every copy of this mutt howling back to hell. <br /><br />Except.. <br /><br />Except for the wonderful comic sty lings of Larry Joe Campbell, America's Greatest Comic Character Actor. This guy plays Belushi's brother-in-law, Andy, and he is gold. How good is he really? Well, aside from being funny, his job is to make Belushi look good. That's like trying to make butt warts look good. But Campbell pulls it off with style. Someone should invent a Nobel Prize in Comic Buffoonery so he can win it every year. Without Larry Joe this show would consist of a slightly vacant looking Courtney Thorne-Smith smacking Belushi over the head with a frying pan while he alternately beats his chest and plays with the straw on the floor of his cage. 5 stars for Larry Joe Campbell designated Comedic Bacon because he improves the flavor of everything he's in! [negative]\n",
      "\n",
      "1st watched 12/7/2002 - 3 out of 10(Dir-Steve Purcell): Typical Mary Kate & Ashley fare with a few more kisses. It looks to me like the girls are getting pretty tired of this stuff and it will be interesting what happens to them if they ever decide to split up and go there own ways. In this episode of their adventures they are interns in Rome for a `fashion' designer who puts them right into the mailroom to learn what working hard is all about(I guess..). Besides the typical flirtations with boys there is nothing much else except the Rome scenario until about ¾ way into the movie when it's finally revealed why they are getting fired, then re-hired, then fired again, then re-hired again. This is definetly made by people who don't understand the corporate world and it shows in their interpretation of it. Maybe the real world will be their next adventure(if there is one.). Even my kids didn't seem to care for this boring `adventure' in the make-believe. Let's see they probably only have a couple of years till their legal adults. We'll see what happens then. [negative]\n",
      "\n",
      "This movie was so poorly written and directed I fell asleep 30 minutes through the movie. The jokes in the movie are corny and even though the plot is interesting at some angles, it is too far fetched and at some points- ridiculous. If you are 11 or older you will overlook the writing in the movie and be disappointed, but if you are 10 or younger this is a film that will capture your attention and be amazed with all the stunts (which I might add are poorly done) and wish you were some warrior to. The casting in this movie wasn't very good, and the music was very disappointing because it was like they were trying to build up the tension but it didn't fit at all. On a scale of 1-10 (10 being excellent, 1 being horrible) the acting in this movie is a 4. Brenda Song is talented in comedy, but with this kind of movie, in some of the more serious scenes, her acting was laughable. When she made some of her \"fighting\" poses, I started laughing out loud. I think the worst thing about this movie is definitely the directing, for example, the part where her enemy turns out to be the person the evil villain is possesing, how her voice turns dark and evil, I think that was incredibly stupid, and how Wendy's (Brenda Song)teachers were all her teachers at school being possessed by monks, that was pretty ridiculous to. So to sumamrize it all, a disappointing movie, but okay if you're 10 or under. [negative]\n",
      "\n",
      "The most interesting thing about Miryang (Secret Sunshine) is the actors. Jeon Do-yeon, as Lee Shin-ae, the main character, is a woman with a young son whose husband has died in a tragic accident, and who leaves Seoul to live in Miryang, which was his home town, with her young son. Jeon's face is very changeable. She is girlish, flirtatious, elegant, aged and sad, desperate and joyous, with it and terribly isolated by turns, and it's all in her face. The film also stars Song Kang-ho as Kim, a man who meets her when her car breaks down coming into Miryang, who happens to run a garage in town, and who follows her around all the time thereafter, despite her apparent lack of interest in his attentions. Song is the biggest star in Korea right now, renowned for his work with Park Chan-wook and Bong Joon-ho (Sympathy for Mr. Vengeance; Memories of Murder and The Host). And yet here he plays a throwaway character, almost a forgotten man. But of course he makes him interesting and curiously appealing. He is the essential ballast to keep Jeon's character from floating away.<br /><br />Lee Shin-ae is a piano teacher. She comes to the new town, which is a neutral place, a kind of poor-man's Seoul, a town \"just like anywhere else,\" as Kim says (just as he is in a way just like anyone else). Her little boy is sprightly, as little boys are, but plainly damaged and withdrawn at times too. His father used to snore, and when he misses him he lies awake, pretending to snore. He goes to school, and Shin-ae meets parents and students and shopkeepers. There is a sense of place in the film, even though the place is in a sense \"anywhere.\" People speak in the local dialect, and everyone knows everything, and Shin-ae's Seoul origin is immediately noticed. Is life really harsher here, away from the big city and its sophistication? Shin-ae seems not to realize the danger she is in.<br /><br />Something terrible happens. And Shin-ae doesn't necessarily deal with it in the best possible way. But it happens and she must face the consequences. But she can't. She goes to pieces. A perpetrator is caught, but that's no consolation. Eventually she becomes so despairing, she relents and goes to a born-again Christian meeting an acquaintance has been pressing her to attend. She finds peace and release with this. But when she decides not only to forgive the perpetrator but to go to the prison to tell him so, that experience is full of ironies and it destroys her all over again. She becomes embittered and desperate and she no longer finds solace in religion. And it gets worse than that.<br /><br />Jeon Do-yeon gives her all in this extremely demanding and protean role. Lee Chang-dong may be a very good director. If an actor of the stature of Song Kang-ho expresses enormous admiration for him, that is convincing. According to Scott Foundas of LA Weekly, Lee's first three films, Green Fish (1997), Peppermint Candy (2000) and Oasis (2002) have marked him out as \"one of the leading figures of his country's recent cinematic renaissance.\" But this is not as successful a film as those of other Korean directors whose work I've seen, such as Yong Sang-Soo, Bong Joon-ho, and the prodigiously, almost perversely gifted Park Chan-wook. It may indeed begin as Foundas says as a kind of \"Asiatic Alice Doesn't Live Here Anymore\" and then \"abruptly and without warning\" turns into \"something of a thriller, and some time after that a nearly Bressonian study in human suffering.\" But that progression not only seems random and indigestible; the film sags and loses its momentum toward the end and then simply fizzles out, with no sense of an ending. There are also weaknesses in the action. Shin-ae takes foolish chances with her son, and makes bad choices all along. If she is destined for madness like Betty in Jean-Jacques Beineix's Betty Blue, which might explain her peculiar and mistaken choices, that isn't something that is properly developed. This is an interesting film, certainly a disturbing one, but one that leaves one doubtful and dissatisfied, after putting one through an emotional wringer.<br /><br />An official selection of the New York Film Festival presented at Lincoln Center, 2007an event that has done right by Korean filmmakers in the recent past. [positive]\n",
      "\n",
      "I saw this film on September 1st, 2005 in Indianapolis. I am one of the judges for the Heartland Film Festival that screens films for their Truly Moving Picture Award. A Truly Moving Picture \"...explores the human journey by artistically expressing hope and respect for the positive values of life.\" Heartland gave that award to this film.<br /><br />This is a story of golf in the early part of the 20th century. At that time, it was the game of upper class and rich \"gentlemen\", and working people could only participate by being caddies at country clubs. With this backdrop, this based-on-a-true-story unfolds with a young, working class boy who takes on the golf establishment and the greatest golfer in the world, Harry Vardon.<br /><br />And the story is inspirational. Against all odds, Francis Ouimet (played by Shia LaBeouf of \"Holes\") gets to compete against the greatest golfers of the U.S. and Great Britain at the 1913 U.S. Open. Francis is ill-prepared, and has a child for a caddy. (The caddy is hilarious and motivational and steals every scene he appears in.) But despite these handicaps, Francis displays courage, spirit, heroism, and humility at this world class event.<br /><br />And, we learn a lot about the early years of golf; for example, the use of small wooden clubs, the layout of the short holes, the manual scoreboard, the golfers swinging with pipes in their mouths, the terrible conditions of the greens and fairways, and the play not being canceled even in torrential rain.<br /><br />This film has stunning cinematography and art direction and editing. And with no big movie stars, the story is somehow more believable.<br /><br />This adds to the inventory of great sports movies in the vein of \"Miracle\" and \"Remember the Titans.\"<br /><br />FYI - There is a Truly Moving Pictures web site where there is a listing of past winners going back 70 years. [positive]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_reviews_w_person = [(x + \" [\" + pred_sentiment[i] + \"]\") for i,x in enumerate(imdb_test[\"text\"]) if imdb_include_person[i]]\n",
    "for i in sample_reviews_w_person[:5]:\n",
    "    print(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58218642",
   "metadata": {},
   "source": [
    "Show the first few reviews that DO NOT make reference to a PERSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "856ee3bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when i first read about \"berlin am meer\" i didn't expect much. but i thought with the right people, the right locations, the right music and fashion you could at least make a trivial movie about the hip berlin everyone seems to be talking about. but eissler failed, it's so ridiculously unauthentic. it's a complete misrepresentation of what it is going on in berlin's so called scene. of course it's not all about hippness, but you should expect more from a movie that's being sold as \"the definite berlin movie\".<br /><br />and apart from all the credibility stuff, it really is a bad movie. mediocre acting and a rather boring plot. interestingly some of the actors have proved in other movies that they are actually quite talented. so it really must be poor directing skills.<br /><br />don't bother watching \"berlin am meer\" unless you are 17, come from some small town in western Germany and want to move to the big city after you finished school. then you might actually find it enjoyable and totally cool. [negative]\n",
      "\n",
      "IT IS A PIECE OF CRAP! not funny at all. during the whole movie nothing ever happens. i almost fell asleep, which in my case happens only if a movie is rally bad. (that is why it didn't get 1 (awful) out of 10 but 2).don't be fooled, like i was, by first review. a waste of money and your time! spend it on other stuff. at this point i'm finished with my review but i have to fill in at least ten lines of text so i will go on.... (ctrl+c, ctrl+v) :))) IT IS A PIECE OF CRAP! not funny at all. during the whole movie nothing ever happens. i almost fell asleep, which in my case happens only if a movie is rally bad. (that is why it didn't get 1 (awful) out of 10 but 2).don't be fooled, like i was, by first review. a waste of money and your time! spend it on other stuff. IT IS A PIECE OF CRAP! not funny at all. during the whole movie nothing ever happens. i almost fell asleep, which in my case happens only if a movie is rally bad. (that is why it didn't get 1 (awful) out of 10 but 2).don't be fooled, like i was, by first review. a waste of money and your time! spend it on other stuff. [negative]\n",
      "\n",
      "I'M BOUT IT(1997)<br /><br />Developed & published by No Limit Films<br /><br />>>Pros: Absolutely none<br /><br />>>Cons: I don't even know where to begin!<br /><br />Plot summary: Master P plays a drug dealer that looks, talks, and acts more like a live-action cartoon character. That's all the plot I got out of this movie.<br /><br />Review: I remember back when I was in the ninth grade during its release and everyone in my class praised this clown called Master P. This movie is so bad, it's not even funny. All the characters in this film are extremely tired stereotypes, the audio is only audible when music plays, and the movie looks like it was videotaped off a public access channel. Luckily, I didn't buy this film like all my other inner-city degenerate classmates.<br /><br />My rating:1 out of 10<br /><br />My verdict: Avoid this video like its a sexually-transmitted disease. [negative]\n",
      "\n",
      "Uwe Boll has done the impossible: create a game adaptation that stays at least somewhat true to the game; he has turned a game full of antisocial and offensive content into a movie full of antisocial and offensive content. So, as an adaptation, it's a success.<br /><br />Unfortunately, it's still Uwe Boll we are dealing with here, so don't expect the movie to be actually any good. while it does have it's moment, \"Postal\" wears out his welcome very fast and becomes a pain to sit through.<br /><br />At its core, Postal is a satire on the United States, as done by a twelve year old kid. Boll seems to think that offensiveness is linearly proportional to comedic value: the more offensive, the funnier, and the more exaggerated the funnier. This results in a movie that sets new levels of tastelessness while being extremely hit and miss. Yes, some gags do work but it seems to be pure luck. High points include the director satirizing himself, and people getting hit very violently by trucks and other vehicles. Low points include..well pretty much everything else.<br /><br />After the initial surprise wears off, Postal simply becomes a bore to watch. Yes there is a good joke every and good point ten minutes, but everything else consists of hordes of annoying characters shooting and chasing each other all over the place for what seems to be an eternity.<br /><br />This probably would have worked as a short movie, but it's just not enough content for something that lasts over 90 minutes (although it feels twice as long). There are nice ideas and nice tries, but they get hopelessly lost in endless and pointless action scenes and content that is offensive just for the sake of it 4/10 [negative]\n",
      "\n",
      "I felt asleep, watching it!!! (and I had tickets for the midnight- premiere) Any questions? The most disturbing scene, as far as I can remember, was the techno-dance-i-dont-know-what-that-was-scene. By the way what an ending!? [negative]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample_reviews_wo_person = [(x + \" [\" + pred_sentiment[i] + \"]\") for i,x in enumerate(imdb_test[\"text\"]) if imdb_include_person[i]==False]\n",
    "for i in sample_reviews_wo_person[:5]:\n",
    "    print(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a719e6",
   "metadata": {},
   "source": [
    "Let's look at the sentiment distribution if we consider only those reviews that make any reference to a person. We can contrast it with the sentiment distribution of all the reviews in the test set. We can see that when a person is mentioned, the chance of a review being a positive one gets higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ed07eb9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mentioning_a_person</th>\n",
       "      <td>2063</td>\n",
       "      <td>1853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all_reviews</th>\n",
       "      <td>2500</td>\n",
       "      <td>2500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     positive  negative\n",
       "mentioning_a_person      2063      1853\n",
       "all_reviews              2500      2500"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = pd.Series(pred_sentiment[np.where(imdb_include_person)]).value_counts()\n",
    "y = pd.Series(pred_sentiment).value_counts()\n",
    "\n",
    "z = pd.concat([x, y], axis=1)\n",
    "z.columns =  [\"mentioning_a_person\", \"all_reviews\"]\n",
    "z = z.transpose()\n",
    "\n",
    "display(z)\n",
    "\n",
    "z.plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4784a9f5",
   "metadata": {},
   "source": [
    "### Sentence-level analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a79c7f",
   "metadata": {},
   "source": [
    "Associating a mention of a person with the sentiment-tag at the review/paragraph level is very imprecise. There is a chance that a movie review is overall positive, but the sentiment of its mentioned director is actually negative. \n",
    "\n",
    "To make the association between a mentioned person and a sentiment value more precise, the sentiment analysis can be done at a sentence level. \n",
    "\n",
    "In the following we perform sentence segmentation of the IMDB reviews in the test data, and repeat the sentiment analysis and NER on the individual sentences. For efficiency sake, we only consider the first 100 reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aba3f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily.\n",
      "\n",
      "But then one day a tragic happenstance occurred.\n",
      "\n",
      "After a White Sox game ended I realized that the remote was all the way on the other side of the room somehow.\n",
      "\n",
      "Now I could have just gotten up and walked across the room to get the remote, or even to the TV to turn the channel.\n",
      "\n",
      "But then why not just get up and walk across the country to watch TV in another state?\n",
      "\n",
      "\"\n",
      "\n",
      "Nuts to that\", I said.\n",
      "\n",
      "So I decided to just hang tight on the couch and take whatever Fate had in store for me.\n",
      "\n",
      "What Fate had in store was an episode of this show, an episode about which I remember very little except that I had once again made a very broad, general sweeping blanket judgment based on zero objective or experiential evidence with nothing whatsoever to back my opinions up with, and once again I was completely right!\n",
      "\n",
      "This show is a total crud-pie!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imdb_test_sentence = []\n",
    "for i in imdb_test[\"text\"][:100]:\n",
    "    doc = nlp(i)\n",
    "    for sent in doc.sents:\n",
    "        imdb_test_sentence.append(sent.text)\n",
    "        \n",
    "temp = [print(i+\"\\n\") for i in imdb_test_sentence[:10]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4babf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_sent_include_person = []\n",
    "\n",
    "for doc in nlp.pipe(imdb_test_sentence, disable=[\"tok2vec\", \"tagger\", \"parser\", \"attribute_ruler\", \"lemmatizer\"]):\n",
    "    imdb_sent_include_person.append(\"PERSON\" in [(ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb760dc",
   "metadata": {},
   "source": [
    "Show some example sentences that mention a person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2eb8e215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily.\n",
      "\n",
      "<br /><br />Except.. <br /><br />Except for the wonderful comic sty lings of Larry Joe Campbell, America's Greatest Comic Character Actor.\n",
      "\n",
      "This guy plays Belushi's brother-in-law, Andy, and he is gold.\n",
      "\n",
      "Without Larry Joe this show would consist of a slightly vacant looking Courtney Thorne-Smith smacking Belushi over the head with a frying pan while he alternately beats his chest and plays with the straw on the floor of his cage.\n",
      "\n",
      "5 stars for Larry Joe Campbell designated Comedic Bacon because he improves the flavor of everything he's in!\n",
      "\n",
      "1st watched 12/7/2002 - 3 out of 10(Dir-Steve Purcell): Typical Mary Kate & Ashley fare with a few more kisses.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "temp = [print(x+\"\\n\") for i,x in enumerate(imdb_test_sentence[:30]) if imdb_sent_include_person[i]==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acf227c",
   "metadata": {},
   "source": [
    "Sentiment prediction at the sentence level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9d31d2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I always wrote this series off as being a complete stink-fest because Jim Belushi was involved in it, and heavily. [positive]\n",
      "\n",
      "<br /><br />Except.. <br /><br />Except for the wonderful comic sty lings of Larry Joe Campbell, America's Greatest Comic Character Actor. [negative]\n",
      "\n",
      "This guy plays Belushi's brother-in-law, Andy, and he is gold. [positive]\n",
      "\n",
      "Without Larry Joe this show would consist of a slightly vacant looking Courtney Thorne-Smith smacking Belushi over the head with a frying pan while he alternately beats his chest and plays with the straw on the floor of his cage. [positive]\n",
      "\n",
      "5 stars for Larry Joe Campbell designated Comedic Bacon because he improves the flavor of everything he's in! [negative]\n",
      "\n",
      "1st watched 12/7/2002 - 3 out of 10(Dir-Steve Purcell): Typical Mary Kate & Ashley fare with a few more kisses. [negative]\n",
      "\n",
      "Brenda Song is talented in comedy, but with this kind of movie, in some of the more serious scenes, her acting was laughable. [positive]\n",
      "\n",
      "I think the worst thing about this movie is definitely the directing, for example, the part where her enemy turns out to be the person the evil villain is possesing, how her voice turns dark and evil, I think that was incredibly stupid, and how Wendy's (Brenda Song)teachers were all her teachers at school being possessed by monks, that was pretty ridiculous to. [positive]\n",
      "\n",
      "The most interesting thing about Miryang (Secret Sunshine) is the actors. [negative]\n",
      "\n",
      "Jeon Do-yeon, as Lee Shin-ae, the main character, is a woman with a young son whose husband has died in a tragic accident, and who leaves Seoul to live in Miryang, which was his home town, with her young son. [positive]\n",
      "\n",
      "The film also stars Song Kang-ho as Kim, a man who meets her when her car breaks down coming into Miryang, who happens to run a garage in town, and who follows her around all the time thereafter, despite her apparent lack of interest in his attentions. [positive]\n",
      "\n",
      "Song is the biggest star in Korea right now, renowned for his work with Park Chan-wook and Bong Joon-ho (Sympathy for Mr. Vengeance; Memories of Murder and The Host). [positive]\n",
      "\n",
      "He is the essential ballast to keep Jeon's character from floating away.<br /><br />Lee [negative]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "imdb_test_sent_df = pd.DataFrame.from_records([ft.get_sentence_vector(i) for i in imdb_test_sentence])\n",
    "pred_sent_sentiment = model.predict(imdb_test_sent_df)\n",
    "\n",
    "temp = [print(x+ \" [\" + pred_sent_sentiment[i] + \"]\\n\") for i,x in enumerate(imdb_test_sentence[:50]) if imdb_sent_include_person[i]==True]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cd5464",
   "metadata": {},
   "source": [
    "### Coreference resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e245e",
   "metadata": {},
   "source": [
    "If we rely only on NER to detect the presence of a mention of a person, we are missing out on many sentence that mentions a person through a coreference. For example, in the review below, the sentence \"*But she's also shrill ...*\" will be left out, even though it mentions Sandra Bernhard implicitly through a coreferencing pronoun \"*she*\". \n",
    "\n",
    "***\n",
    "\n",
    "\"*Film version of Sandra Bernhard's one-woman off-Broadway show is gaspingly pretentious. Sandra spoofs lounge acts and superstars, but her sense of irony is only fitfully interesting, and fitfully funny. Her fans will say she's scathingly honest, and that may be true. But she's also shrill, with an unapologetic, in-your-face bravado that isn't well-suited to a film in this genre. She doesn't want to make nice--and she's certainly not out to make friends--and that's always going to rub a lot of people the wrong way. But even if you meet her halfway, her material here is seriously lacking. Filmmaker Nicolas Roeg served as executive producer and, though not directed by him, the film does have his chilly, detached signature style all over it. Bernhard co-wrote the show with director John Boskovich; their oddest touch was in having all of Sandra's in-house audiences looking completely bored--a feeling many real viewers will most likely share. 1/2 from xxxx*\"\n",
    "\n",
    "***\n",
    "\n",
    "To address this issue, we can perform an NLP technique called *Coreference Resolution* to indicate that the \"*she*\" in the sentence \"*But she's also shrill ...*\" is referring to Sandra Bernhard (who is a PERSON entity). This way, we will be able to include the sentence in the sentiment analysis. \n",
    "\n",
    "We do not include the code for the above coreference resolution analysis. However, we show below a figure that shows the result of applying coreference resolution on the above review, using AllenNLP demo (https://demo.allennlp.org/coreference-resolution).\n",
    "\n",
    "![Coreference Resolution](Images/Coreference.png)\n",
    "\n",
    "Coreference resolution model or dataset however is not readily available for SEA languages!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a06b75",
   "metadata": {},
   "source": [
    "### Constituency parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162e9720",
   "metadata": {},
   "source": [
    "To make the association between a person and a sentiment value more precise, we have moved from a review/paragraph-level analysis to a sentence-level analysis. However, we do not need to stop there. We can push it further to a clause-level analysis. This can be done using *Constituency Parsing*. For example, this sample sentence: *Sandra spoofs lounge acts and superstars, but her sense of irony is only fitfully interesting, and fitfully funny* can be broken down into multiple clauses by a constituency parser as shown below.\n",
    "\n",
    "![Constituency Parsing](Images/Constituency.png)\n",
    "\n",
    "We can perform sentiment analysis at the clause level, e.g. \"*Sandra spoofs lounge acts and superstars* \\[positive\\]\", \"*her sense of irony is only fitfully interesting* \\[negative\\]\" etc; connecting more precisely the sentiment values and the PERSON entities. \n",
    "\n",
    "Just like coreference resolution, models or datasets for constituency parsing are hard to find for SEA languages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da8d2b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
